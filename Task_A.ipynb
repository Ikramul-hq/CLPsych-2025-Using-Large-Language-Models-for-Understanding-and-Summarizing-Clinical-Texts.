{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10964769,"sourceType":"datasetVersion","datasetId":6821926},{"sourceId":10964772,"sourceType":"datasetVersion","datasetId":6821929}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\ndef load_all_timelines(data_dir):\n    \"\"\"Load all JSON files from a directory into a list of timelines\"\"\"\n    timelines = []\n    for filename in os.listdir(data_dir):\n        if filename.endswith('.json'):\n            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:\n                timeline = json.load(f)\n                timelines.append(timeline)\n    return timelines\n\ndef create_training_dataset(timelines):\n    \"\"\"Extract posts with their evidence annotations into a DataFrame\"\"\"\n    data = []\n    for timeline in timelines:\n        timeline_id = timeline[\"timeline_id\"]\n        for post in timeline[\"posts\"]:\n            post_id = post[\"post_id\"]\n            post_text = post[\"post\"]\n            \n            # Skip posts without evidence annotations\n            if \"evidence\" not in post:\n                continue\n                \n            # Extract adaptive evidence spans\n            adaptive_evidence = []\n            if \"adaptive-state\" in post[\"evidence\"]:\n                for component, details in post[\"evidence\"][\"adaptive-state\"].items():\n                    if \"highlighted_evidence\" in details:\n                        adaptive_evidence.append(details[\"highlighted_evidence\"])\n            \n            # Extract maladaptive evidence spans\n            maladaptive_evidence = []\n            if \"maladaptive-state\" in post[\"evidence\"]:\n                for component, details in post[\"evidence\"][\"maladaptive-state\"].items():\n                    if \"highlighted_evidence\" in details:\n                        maladaptive_evidence.append(details[\"highlighted_evidence\"])\n            \n            data.append({\n                \"timeline_id\": timeline_id,\n                \"post_id\": post_id,\n                \"text\": post_text,\n                \"adaptive_evidence\": adaptive_evidence,\n                \"maladaptive_evidence\": maladaptive_evidence\n            })\n    \n    return pd.DataFrame(data)\n\n# Load all training timelines\ntrain_timelines = load_all_timelines(\"/kaggle/input/train-dataset-1\")\ntrain_df = create_training_dataset(train_timelines)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.048606Z","iopub.execute_input":"2025-03-08T21:25:21.048930Z","iopub.status.idle":"2025-03-08T21:25:21.101698Z","shell.execute_reply.started":"2025-03-08T21:25:21.048906Z","shell.execute_reply":"2025-03-08T21:25:21.100972Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize\nnltk.download('punkt')\n\ndef analyze_dataset(df):\n    \"\"\"Analyze the training dataset to understand its characteristics\"\"\"\n    print(f\"Total posts: {len(df)}\")\n    print(f\"Posts with adaptive evidence: {sum(df['adaptive_evidence'].apply(len) > 0)}\")\n    print(f\"Posts with maladaptive evidence: {sum(df['maladaptive_evidence'].apply(len) > 0)}\")\n    \n    # Create binary labels for classification\n    df['has_adaptive'] = df['adaptive_evidence'].apply(lambda x: 1 if len(x) > 0 else 0)\n    df['has_maladaptive'] = df['maladaptive_evidence'].apply(lambda x: 1 if len(x) > 0 else 0)\n    \n    # Tokenize posts into sentences for later use\n    df['sentences'] = df['text'].apply(sent_tokenize)\n    \n    return df\n\n# Analyze and preprocess the dataset\ntrain_df = analyze_dataset(train_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.102863Z","iopub.execute_input":"2025-03-08T21:25:21.103174Z","iopub.status.idle":"2025-03-08T21:25:21.181124Z","shell.execute_reply.started":"2025-03-08T21:25:21.103153Z","shell.execute_reply":"2025-03-08T21:25:21.180476Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nTotal posts: 343\nPosts with adaptive evidence: 169\nPosts with maladaptive evidence: 179\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\ndef engineer_features(df, feature_type=\"tfidf\"):\n    \"\"\"Create features for binary classification\"\"\"\n    if feature_type == \"tfidf\":\n        # TF-IDF features\n        vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n        X = vectorizer.fit_transform(df['text'])\n        feature_names = vectorizer.get_feature_names_out()\n    else:\n        # Add other feature types if needed (e.g., BERT embeddings)\n        pass\n    \n    return X, vectorizer, feature_names\n\n# Split data into train and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Create feature matrices\nX_train, vectorizer, feature_names = engineer_features(train_data)\nX_val = vectorizer.transform(val_data['text'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.182933Z","iopub.execute_input":"2025-03-08T21:25:21.183151Z","iopub.status.idle":"2025-03-08T21:25:21.282140Z","shell.execute_reply.started":"2025-03-08T21:25:21.183132Z","shell.execute_reply":"2025-03-08T21:25:21.281458Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ndef train_binary_classifiers(X_train, y_train_adaptive, y_train_maladaptive, \n                             X_val, y_val_adaptive, y_val_maladaptive):\n    \"\"\"Train separate classifiers for adaptive and maladaptive states\"\"\"\n    # Adaptive classifier\n    adaptive_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    adaptive_clf.fit(X_train, y_train_adaptive)\n    adaptive_preds = adaptive_clf.predict(X_val)\n    \n    # Maladaptive classifier\n    maladaptive_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    maladaptive_clf.fit(X_train, y_train_maladaptive)\n    maladaptive_preds = maladaptive_clf.predict(X_val)\n    \n    # Evaluate classifiers\n    print(\"Adaptive Classifier Performance:\")\n    print(classification_report(y_val_adaptive, adaptive_preds))\n    \n    print(\"Maladaptive Classifier Performance:\")\n    print(classification_report(y_val_maladaptive, maladaptive_preds))\n    \n    return adaptive_clf, maladaptive_clf\n\n# Train classifiers\nadaptive_clf, maladaptive_clf = train_binary_classifiers(\n    X_train, train_data['has_adaptive'], train_data['has_maladaptive'],\n    X_val, val_data['has_adaptive'], val_data['has_maladaptive']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.283076Z","iopub.execute_input":"2025-03-08T21:25:21.283354Z","iopub.status.idle":"2025-03-08T21:25:21.827498Z","shell.execute_reply.started":"2025-03-08T21:25:21.283322Z","shell.execute_reply":"2025-03-08T21:25:21.826366Z"}},"outputs":[{"name":"stdout","text":"Adaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.79      0.81      0.80        37\n           1       0.77      0.75      0.76        32\n\n    accuracy                           0.78        69\n   macro avg       0.78      0.78      0.78        69\nweighted avg       0.78      0.78      0.78        69\n\nMaladaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.94      0.83      0.88        41\n           1       0.79      0.93      0.85        28\n\n    accuracy                           0.87        69\n   macro avg       0.87      0.88      0.87        69\nweighted avg       0.88      0.87      0.87        69\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def calculate_feature_importance_simple(clf, feature_names):\n    \"\"\"Calculate feature importance using the classifier's built-in feature_importances_\"\"\"\n    if not hasattr(clf, 'feature_importances_'):\n        raise ValueError(\"Classifier does not have feature_importances_ attribute\")\n    \n    importance_scores = clf.feature_importances_\n    \n    # Create a mapping of features to importance scores\n    feature_importance = {feature_names[i]: importance_scores[i] \n                         for i in range(len(feature_names))}\n    \n    return feature_importance\n\n# Calculate feature importance for adaptive classifier\nadaptive_importance = calculate_feature_importance_simple(adaptive_clf, feature_names)\nprint(f\"Top 5 important features for adaptive states: {sorted(adaptive_importance.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n\n# Calculate feature importance for maladaptive classifier\nmaladaptive_importance = calculate_feature_importance_simple(maladaptive_clf, feature_names)\nprint(f\"Top 5 important features for maladaptive states: {sorted(maladaptive_importance.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.828765Z","iopub.execute_input":"2025-03-08T21:25:21.829127Z","iopub.status.idle":"2025-03-08T21:25:21.870756Z","shell.execute_reply.started":"2025-03-08T21:25:21.829093Z","shell.execute_reply":"2025-03-08T21:25:21.869989Z"},"_kg_hide-output":false},"outputs":[{"name":"stdout","text":"Top 5 important features for adaptive states: [('and', 0.022689654908040886), ('but', 0.021444647353222553), ('it', 0.018397119002538157), ('to', 0.016057036870414175), ('for', 0.014616723314670446)]\nTop 5 important features for maladaptive states: [('and', 0.02563150227239303), ('to', 0.02274935575225972), ('it', 0.018220202868338312), ('be', 0.016732570023576965), ('of', 0.01626467195205366)]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse\n\ndef extract_evidence_spans(post_text, clf, vectorizer, feature_names, \n                           importance_threshold=0.01, top_n=3, feature_importance=None):\n    \"\"\"\n    Extract evidence spans for a post using feature importance\n    \n    Parameters:\n    -----------\n    post_text : str\n        The text of the post to analyze\n    clf : classifier\n        Trained classifier model\n    vectorizer : TfidfVectorizer or similar\n        The vectorizer used to convert text to features\n    feature_names : list\n        Names of features\n    importance_threshold : float\n        Threshold for considering a feature important\n    top_n : int\n        Number of top sentences to return\n    feature_importance : dict, optional\n        Pre-calculated feature importance dictionary\n    \"\"\"\n    # Vectorize the post\n    post_vector = vectorizer.transform([post_text])\n    \n    # Predict if post contains evidence\n    try:\n        has_evidence = clf.predict(post_vector)[0]\n    except Exception as e:\n        print(f\"Prediction error: {str(e)}\")\n        return []\n    \n    if not has_evidence:\n        return []\n    \n    # Use pre-calculated feature importance if provided\n    if feature_importance is not None:\n        post_importance = feature_importance\n    else:\n        try:\n            # Use classifier's built-in feature importance instead of SHAP\n            # This avoids the sparse matrix issues with SHAP\n            if hasattr(clf, 'feature_importances_'):\n                importance_scores = clf.feature_importances_\n                post_importance = {feature_names[i]: importance_scores[i] \n                                  for i in range(len(feature_names))}\n            else:\n                # If no feature importance available, use coefficient values for linear models\n                if hasattr(clf, 'coef_'):\n                    coef = clf.coef_[0] if len(clf.coef_.shape) > 1 else clf.coef_\n                    post_importance = {feature_names[i]: abs(coef[i]) \n                                      for i in range(len(feature_names))}\n                else:\n                    # Last resort: give equal importance to all features present in this post\n                    post_importance = {}\n                    post_vector_array = post_vector.toarray()[0]\n                    for i, val in enumerate(post_vector_array):\n                        if val > 0:\n                            post_importance[feature_names[i]] = val\n        except Exception as e:\n            print(f\"Feature importance calculation error: {str(e)}\")\n            # Create a simple importance score based on TF-IDF values\n            post_importance = {}\n            for i, val in enumerate(post_vector.toarray()[0]):\n                if val > 0:\n                    post_importance[feature_names[i]] = val\n    \n    # Find important sentences\n    important_sentences = find_important_sentences(\n        post_text, post_importance, importance_threshold\n    )\n    \n    # Return top N sentences as evidence spans\n    spans = [s['sentence'] for s in important_sentences[:top_n] if s['score'] > 0]\n    \n    # Ensure spans are actually in the original text\n    validated_spans = [span for span in spans if span in post_text]\n    \n    return validated_spans\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.872934Z","iopub.execute_input":"2025-03-08T21:25:21.873157Z","iopub.status.idle":"2025-03-08T21:25:21.881253Z","shell.execute_reply.started":"2025-03-08T21:25:21.873138Z","shell.execute_reply":"2025-03-08T21:25:21.880368Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def consolidate_spans(spans, post_text):\n    \"\"\"Merge overlapping spans and ensure they are continuous in the original text\"\"\"\n    if not spans:\n        return []\n    \n    # Sort spans by their position in the original text\n    sorted_spans = sorted(spans, key=lambda span: post_text.find(span))\n    \n    # Merge spans that are adjacent or overlapping in the original text\n    consolidated = []\n    current_start = post_text.find(sorted_spans[0])\n    current_end = current_start + len(sorted_spans[0])\n    current_span = sorted_spans[0]\n    \n    for span in sorted_spans[1:]:\n        span_start = post_text.find(span)\n        span_end = span_start + len(span)\n        \n        # If spans overlap or are adjacent, merge them\n        if span_start <= current_end + 5:  # Allow small gaps (5 chars)\n            merged_end = max(current_end, span_end)\n            current_span = post_text[current_start:merged_end]\n            current_end = merged_end\n        else:\n            consolidated.append(current_span)\n            current_start = span_start\n            current_end = span_end\n            current_span = span\n    \n    consolidated.append(current_span)\n    return consolidated\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.882640Z","iopub.execute_input":"2025-03-08T21:25:21.882876Z","iopub.status.idle":"2025-03-08T21:25:21.891953Z","shell.execute_reply.started":"2025-03-08T21:25:21.882858Z","shell.execute_reply":"2025-03-08T21:25:21.891152Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def process_test_timeline(timeline, adaptive_clf, maladaptive_clf, vectorizer, feature_names, \n                         adaptive_importance=None, maladaptive_importance=None):\n    \"\"\"Process a test timeline to extract evidence spans for each post\"\"\"\n    timeline_id = timeline[\"timeline_id\"]\n    result = {\n        \"timeline_level\": {\"summary\": \"\"},  # Will be filled by Task C\n        \"post_level\": {}\n    }\n    \n    for post in timeline[\"posts\"]:\n        post_id = post[\"post_id\"]\n        post_text = post[\"post\"] if \"post\" in post else \"\"\n        \n        if not post_text:\n            # Handle empty posts\n            result[\"post_level\"][post_id] = {\n                \"adaptive_evidence\": [],\n                \"maladaptive_evidence\": [],\n                \"summary\": \"\",\n                \"wellbeing_score\": None\n            }\n            continue\n            \n        # Extract adaptive evidence\n        adaptive_spans = extract_evidence_spans(\n            post_text, adaptive_clf, vectorizer, feature_names,\n            feature_importance=adaptive_importance\n        )\n        adaptive_spans = consolidate_spans(adaptive_spans, post_text)\n        \n        # Extract maladaptive evidence\n        maladaptive_spans = extract_evidence_spans(\n            post_text, maladaptive_clf, vectorizer, feature_names,\n            feature_importance=maladaptive_importance\n        )\n        maladaptive_spans = consolidate_spans(maladaptive_spans, post_text)\n        \n        # Add to results\n        result[\"post_level\"][post_id] = {\n            \"adaptive_evidence\": adaptive_spans,\n            \"maladaptive_evidence\": maladaptive_spans,\n            \"summary\": \"\",  # Will be filled by Task B\n            \"wellbeing_score\": None  # Will be filled by Task A.2\n        }\n    \n    return timeline_id, result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.892879Z","iopub.execute_input":"2025-03-08T21:25:21.893180Z","iopub.status.idle":"2025-03-08T21:25:21.904574Z","shell.execute_reply.started":"2025-03-08T21:25:21.893155Z","shell.execute_reply":"2025-03-08T21:25:21.903883Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def calculate_feature_importance_simple(clf, feature_names):\n    \"\"\"Calculate feature importance using the classifier's built-in feature_importances_\"\"\"\n    if hasattr(clf, 'feature_importances_'):\n        importance_scores = clf.feature_importances_\n    elif hasattr(clf, 'coef_'):\n        coef = clf.coef_[0] if len(clf.coef_.shape) > 1 else clf.coef_\n        importance_scores = np.abs(coef)\n    else:\n        raise ValueError(\"Classifier does not have feature_importances_ or coef_ attribute\")\n    \n    # Create a mapping of features to importance scores\n    feature_importance = {feature_names[i]: float(importance_scores[i]) \n                         for i in range(len(feature_names))}\n    \n    return feature_importance\n\ndef run_full_pipeline(train_dir, test_dir, output_path, team_name=\"MyTeam\"):\n    \"\"\"Run the complete Task A.1 pipeline from training to submission generation\"\"\"\n    print(\"Loading training data...\")\n    train_timelines = load_all_timelines(train_dir)\n    train_df = create_training_dataset(train_timelines)\n    train_df = analyze_dataset(train_df)\n    \n    print(\"Training classifiers...\")\n    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n    X_train, vectorizer, feature_names = engineer_features(train_data)\n    X_val = vectorizer.transform(val_data['text'])\n    \n    adaptive_clf, maladaptive_clf = train_binary_classifiers(\n        X_train, train_data['has_adaptive'], train_data['has_maladaptive'],\n        X_val, val_data['has_adaptive'], val_data['has_maladaptive']\n    )\n    \n    print(\"Calculating feature importance...\")\n    # Calculate feature importance using the simplified method\n    try:\n        adaptive_importance = calculate_feature_importance_simple(adaptive_clf, feature_names)\n        print(\"Feature importance for adaptive classifier calculated successfully\")\n    except Exception as e:\n        print(f\"Error calculating importance for adaptive classifier: {str(e)}\")\n        adaptive_importance = None\n        \n    try:\n        maladaptive_importance = calculate_feature_importance_simple(maladaptive_clf, feature_names)\n        print(\"Feature importance for maladaptive classifier calculated successfully\")\n    except Exception as e:\n        print(f\"Error calculating importance for maladaptive classifier: {str(e)}\")\n        maladaptive_importance = None\n    \n    print(\"Processing test data...\")\n    test_timelines = load_all_timelines(test_dir)\n    \n    submission = {}\n    for timeline in tqdm(test_timelines, desc=\"Processing test timelines\"):\n        timeline_id, result = process_test_timeline(\n            timeline, adaptive_clf, maladaptive_clf, vectorizer, feature_names,\n            adaptive_importance, maladaptive_importance\n        )\n        submission[timeline_id] = result\n    \n    print(\"Saving submission...\")\n    os.makedirs(output_path, exist_ok=True)\n    output_file = os.path.join(output_path, f\"{team_name}_1.json\")\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(submission, f, ensure_ascii=False, indent=2)\n    \n    print(f\"Task A.1 processing complete! Submission saved to {output_file}\")\n    return submission\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.905372Z","iopub.execute_input":"2025-03-08T21:25:21.905685Z","iopub.status.idle":"2025-03-08T21:25:21.921467Z","shell.execute_reply.started":"2025-03-08T21:25:21.905664Z","shell.execute_reply":"2025-03-08T21:25:21.920108Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def evaluate_evidence_extraction(val_data, predictions, metric=\"bertscore\"):\n    \"\"\"Evaluate evidence extraction performance using BERTScore\"\"\"\n    from bert_score import score\n    \n    adaptive_scores = []\n    maladaptive_scores = []\n    \n    for i, row in val_data.iterrows():\n        post_id = row['post_id']\n        if post_id in predictions:\n            # Evaluate adaptive evidence\n            gold_adaptive = row['adaptive_evidence']\n            pred_adaptive = predictions[post_id]['adaptive_evidence']\n            \n            if gold_adaptive and pred_adaptive:\n                P, R, F1 = score(pred_adaptive, gold_adaptive, lang=\"en\")\n                adaptive_scores.append(R.mean().item())  # Use recall as per CLPsych evaluation\n            \n            # Evaluate maladaptive evidence\n            gold_maladaptive = row['maladaptive_evidence']\n            pred_maladaptive = predictions[post_id]['maladaptive_evidence']\n            \n            if gold_maladaptive and pred_maladaptive:\n                P, R, F1 = score(pred_maladaptive, gold_maladaptive, lang=\"en\")\n                maladaptive_scores.append(R.mean().item())\n    \n    return {\n        \"adaptive_recall\": np.mean(adaptive_scores) if adaptive_scores else 0,\n        \"maladaptive_recall\": np.mean(maladaptive_scores) if maladaptive_scores else 0,\n        \"overall_recall\": np.mean(adaptive_scores + maladaptive_scores) if adaptive_scores + maladaptive_scores else 0\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.922608Z","iopub.execute_input":"2025-03-08T21:25:21.922947Z","iopub.status.idle":"2025-03-08T21:25:21.939614Z","shell.execute_reply.started":"2025-03-08T21:25:21.922913Z","shell.execute_reply":"2025-03-08T21:25:21.938744Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndef tune_classifiers(X_train, y_train):\n    \"\"\"Find optimal hyperparameters for the classifiers\"\"\"\n    param_grid = {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [None, 10, 20, 30],\n        'min_samples_split': [2, 5, 10]\n    }\n    \n    grid_search = GridSearchCV(\n        RandomForestClassifier(random_state=42),\n        param_grid,\n        cv=5,\n        scoring='f1',\n        n_jobs=-1\n    )\n    \n    grid_search.fit(X_train, y_train)\n    return grid_search.best_estimator_, grid_search.best_params_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.940393Z","iopub.execute_input":"2025-03-08T21:25:21.940772Z","iopub.status.idle":"2025-03-08T21:25:21.958013Z","shell.execute_reply.started":"2025-03-08T21:25:21.940719Z","shell.execute_reply":"2025-03-08T21:25:21.956287Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def extract_bert_features(texts, model_name=\"emilyalsentzer/Bio_ClinicalBERT\"):\n    \"\"\"Extract BERT embeddings as features\"\"\"\n    from transformers import AutoTokenizer, AutoModel\n    import torch\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name)\n    \n    embeddings = []\n    for text in tqdm(texts, desc=\"Extracting BERT embeddings\"):\n        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        # Use CLS token embedding as document representation\n        embeddings.append(outputs.last_hidden_state[:, 0, :].numpy().flatten())\n    \n    return np.array(embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.959105Z","iopub.execute_input":"2025-03-08T21:25:21.959444Z","iopub.status.idle":"2025-03-08T21:25:21.970715Z","shell.execute_reply.started":"2025-03-08T21:25:21.959392Z","shell.execute_reply":"2025-03-08T21:25:21.969674Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def generate_final_submission(test_dir, output_dir, team_name, model_params):\n    \"\"\"Generate the final submission file for Task A.1\"\"\"\n    # Load trained models and vectorizers\n    adaptive_clf = model_params['adaptive_clf']\n    maladaptive_clf = model_params['maladaptive_clf']\n    vectorizer = model_params['vectorizer']\n    feature_names = model_params['feature_names']\n    \n    # Process test timelines\n    test_timelines = load_all_timelines(test_dir)\n    submission = {}\n    \n    for timeline in tqdm(test_timelines, desc=\"Generating final predictions\"):\n        timeline_id, result = process_test_timeline(\n            timeline, adaptive_clf, maladaptive_clf, vectorizer, feature_names\n        )\n        submission[timeline_id] = result\n    \n    # Save submission file\n    output_file = os.path.join(output_dir, f\"{team_name}_TaskA1.json\")\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(submission, f, ensure_ascii=False, indent=2)\n    \n    print(f\"Final submission saved to {output_file}\")\n    return submission\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.971361Z","iopub.execute_input":"2025-03-08T21:25:21.972131Z","iopub.status.idle":"2025-03-08T21:25:21.985591Z","shell.execute_reply.started":"2025-03-08T21:25:21.972098Z","shell.execute_reply":"2025-03-08T21:25:21.984558Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Configuration\n    TRAIN_DIR = \"/kaggle/input/train-dataset-1\"\n    TEST_DIR = \"/kaggle/input/test-dataset-1\"\n    OUTPUT_DIR = \"/kaggle/working/\"\n    TEAM_NAME = \"CIOL\"\n    \n    # Run the complete pipeline\n    submission = run_full_pipeline(TRAIN_DIR, TEST_DIR, OUTPUT_DIR, TEAM_NAME)\n    \n    print(\"Task A.1 completed successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:25:21.989291Z","iopub.execute_input":"2025-03-08T21:25:21.989639Z","iopub.status.idle":"2025-03-08T21:25:24.087087Z","shell.execute_reply.started":"2025-03-08T21:25:21.989607Z","shell.execute_reply":"2025-03-08T21:25:24.086158Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nTotal posts: 343\nPosts with adaptive evidence: 169\nPosts with maladaptive evidence: 179\nTraining classifiers...\nAdaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.79      0.81      0.80        37\n           1       0.77      0.75      0.76        32\n\n    accuracy                           0.78        69\n   macro avg       0.78      0.78      0.78        69\nweighted avg       0.78      0.78      0.78        69\n\nMaladaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.94      0.83      0.88        41\n           1       0.79      0.93      0.85        28\n\n    accuracy                           0.87        69\n   macro avg       0.87      0.88      0.87        69\nweighted avg       0.88      0.87      0.87        69\n\nCalculating feature importance...\nFeature importance for adaptive classifier calculated successfully\nFeature importance for maladaptive classifier calculated successfully\nProcessing test data...\n","output_type":"stream"},{"name":"stderr","text":"Processing test timelines: 100%|██████████| 10/10 [00:01<00:00,  7.55it/s]","output_type":"stream"},{"name":"stdout","text":"Saving submission...\nTask A.1 processing complete! Submission saved to /kaggle/working/CIOL_1.json\nTask A.1 completed successfully!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import json\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\ndef extract_wellbeing_data(timelines):\n    \"\"\"Extract posts with well-being scores from training timelines\"\"\"\n    data = []\n    for timeline in timelines:\n        timeline_id = timeline[\"timeline_id\"]\n        prev_posts = []  # To store previous posts for contextual features\n        \n        for i, post in enumerate(timeline[\"posts\"]):\n            post_id = post[\"post_id\"]\n            post_text = post[\"post\"]\n            \n            # Skip posts without well-being annotations\n            if \"Well-being\" not in post or post[\"Well-being\"] is None:\n                prev_posts.append(post_text)\n                continue\n                \n            wellbeing_score = post[\"Well-being\"]\n            \n            # Extract adaptive and maladaptive evidence\n            adaptive_evidence = []\n            maladaptive_evidence = []\n            if \"evidence\" in post:\n                if \"adaptive-state\" in post[\"evidence\"]:\n                    for component, details in post[\"evidence\"][\"adaptive-state\"].items():\n                        if \"highlighted_evidence\" in details:\n                            adaptive_evidence.append(details[\"highlighted_evidence\"])\n                \n                if \"maladaptive-state\" in post[\"evidence\"]:\n                    for component, details in post[\"evidence\"][\"maladaptive-state\"].items():\n                        if \"highlighted_evidence\" in details:\n                            maladaptive_evidence.append(details[\"highlighted_evidence\"])\n            \n            # Get previous posts context (last 3 posts)\n            context = prev_posts[-3:] if prev_posts else []\n            \n            data.append({\n                \"timeline_id\": timeline_id,\n                \"post_id\": post_id,\n                \"post_index\": i,\n                \"text\": post_text,\n                \"adaptive_evidence\": adaptive_evidence,\n                \"maladaptive_evidence\": maladaptive_evidence,\n                \"previous_posts\": context,\n                \"wellbeing_score\": wellbeing_score\n            })\n            \n            # Update previous posts\n            prev_posts.append(post_text)\n    \n    return pd.DataFrame(data)\n\n# Load all training timelines\ndef load_all_timelines(data_dir):\n    \"\"\"Load all JSON files from a directory into a list of timelines\"\"\"\n    timelines = []\n    for filename in os.listdir(data_dir):\n        if filename.endswith('.json'):\n            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:\n                timeline = json.load(f)\n                timelines.append(timeline)\n    return timelines\n\n# Load and prepare data\ntrain_timelines = load_all_timelines(\"/kaggle/input/train-dataset-1\")\nwellbeing_df = extract_wellbeing_data(train_timelines)\n\n# Analyze well-being score distribution\nscore_distribution = wellbeing_df['wellbeing_score'].value_counts().sort_index()\nprint(\"Well-being score distribution:\")\nprint(score_distribution)\n\n# Split data into training and validation sets\ntrain_data, val_data = train_test_split(wellbeing_df, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:56:47.225569Z","iopub.execute_input":"2025-03-08T21:56:47.225892Z","iopub.status.idle":"2025-03-08T21:56:47.337066Z","shell.execute_reply.started":"2025-03-08T21:56:47.225870Z","shell.execute_reply":"2025-03-08T21:56:47.336070Z"}},"outputs":[{"name":"stdout","text":"Well-being score distribution:\nwellbeing_score\n1     7\n2    13\n3    18\n4    38\n5    32\n6    30\n7    46\n8    13\n9     2\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Download required NLTK resources\nnltk.download('vader_lexicon')\nnltk.download('punkt')\n\ndef extract_wellbeing_features(df):\n    \"\"\"\n    Extract features relevant to well-being prediction\n    \n    Features include:\n    - Text features (length, sentiment)\n    - Evidence-based features (presence, count, ratio)\n    - Previous post context features\n    - Content-based features (mentions of specific topics)\n    \"\"\"\n    # Initialize sentiment analyzer\n    sid = SentimentIntensityAnalyzer()\n    \n    # Create feature DataFrame\n    features = pd.DataFrame()\n    \n    # 1. Basic text features\n    features['text_length'] = df['text'].apply(len)\n    features['word_count'] = df['text'].apply(lambda x: len(x.split()))\n    features['sent_count'] = df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))\n    \n    # 2. Sentiment features\n    features['sentiment_neg'] = df['text'].apply(lambda x: sid.polarity_scores(x)['neg'])\n    features['sentiment_neu'] = df['text'].apply(lambda x: sid.polarity_scores(x)['neu'])\n    features['sentiment_pos'] = df['text'].apply(lambda x: sid.polarity_scores(x)['pos'])\n    features['sentiment_compound'] = df['text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n    \n    # 3. Evidence-based features\n    features['has_adaptive'] = df['adaptive_evidence'].apply(lambda x: 1 if len(x) > 0 else 0)\n    features['has_maladaptive'] = df['maladaptive_evidence'].apply(lambda x: 1 if len(x) > 0 else 0)\n    features['adaptive_count'] = df['adaptive_evidence'].apply(len)\n    features['maladaptive_count'] = df['maladaptive_evidence'].apply(len)\n    \n    # Calculate ratio of adaptive to total evidence spans\n    features['adaptive_ratio'] = features.apply(\n        lambda row: row['adaptive_count'] / (row['adaptive_count'] + row['maladaptive_count']) \n        if (row['adaptive_count'] + row['maladaptive_count']) > 0 else 0.5,\n        axis=1\n    )\n    \n    # 4. Context features (if previous posts exist)\n    features['has_prev_posts'] = df['previous_posts'].apply(lambda x: 1 if len(x) > 0 else 0)\n    features['prev_posts_count'] = df['previous_posts'].apply(len)\n    \n    # 5. Content-based features\n    # Detect mentions of specific topics related to well-being\n    # Social functioning\n    features['mentions_friends'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(friend|friends|social|relationship|relationships)\\b', x.lower()) else 0\n    )\n    features['mentions_family'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(family|parent|parents|mom|dad|sister|brother|sibling)\\b', x.lower()) else 0\n    )\n    \n    # Occupational functioning\n    features['mentions_work'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(work|job|career|school|college|university|study|studies)\\b', x.lower()) else 0\n    )\n    \n    # Psychological functioning\n    features['mentions_mental_health'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(depress|anxiety|stress|mental|therapy|therapist|psychologist|psychiatrist)\\b', \n                                x.lower()) else 0\n    )\n    features['mentions_suicide'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(suicid|kill myself|end my life|die|death)\\b', x.lower()) else 0\n    )\n    features['mentions_self_harm'] = df['text'].apply(\n        lambda x: 1 if re.search(r'\\b(cut|cutting|self-harm|hurt myself|harm myself)\\b', x.lower()) else 0\n    )\n    \n    return features\n\n# Extract features from training and validation data\ntrain_features = extract_wellbeing_features(train_data)\nval_features = extract_wellbeing_features(val_data)\n\n# Add text vectorization features\nvectorizer = TfidfVectorizer(max_features=500, stop_words='english')\ntrain_tfidf = vectorizer.fit_transform(train_data['text'])\nval_tfidf = vectorizer.transform(val_data['text'])\n\n# Convert sparse matrices to DataFrames\ntrain_tfidf_df = pd.DataFrame(\n    train_tfidf.toarray(), \n    columns=[f'tfidf_{i}' for i in range(train_tfidf.shape[1])]\n)\nval_tfidf_df = pd.DataFrame(\n    val_tfidf.toarray(), \n    columns=[f'tfidf_{i}' for i in range(val_tfidf.shape[1])]\n)\n\n# Combine all features\ntrain_features_full = pd.concat([train_features, train_tfidf_df], axis=1)\nval_features_full = pd.concat([val_features, val_tfidf_df], axis=1)\n\n# Prepare target values\ntrain_target = train_data['wellbeing_score']\nval_target = val_data['wellbeing_score']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T21:57:09.167280Z","iopub.execute_input":"2025-03-08T21:57:09.167677Z","iopub.status.idle":"2025-03-08T21:57:10.689630Z","shell.execute_reply.started":"2025-03-08T21:57:09.167650Z","shell.execute_reply":"2025-03-08T21:57:10.688892Z"}},"outputs":[{"name":"stderr","text":"The twython library has not been installed. Some functionality from the twitter package will not be available.\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\n\ndef align_features_and_targets(features_df, targets_series):\n    \"\"\"\n    Ensure features and targets are properly aligned with the same number of samples\n    \n    Parameters:\n    -----------\n    features_df : DataFrame\n        Feature dataframe\n    targets_series : Series\n        Target values series\n    \n    Returns:\n    --------\n    tuple: (aligned_features, aligned_targets)\n    \"\"\"\n    print(f\"Original features shape: {features_df.shape}\")\n    print(f\"Original targets shape: {targets_series.shape}\")\n    \n    # Get the intersection of indices\n    common_indices = features_df.index.intersection(targets_series.index)\n    print(f\"Number of common indices: {len(common_indices)}\")\n    \n    # Filter both dataframes to only include common indices\n    aligned_features = features_df.loc[common_indices]\n    aligned_targets = targets_series.loc[common_indices]\n    \n    print(f\"Aligned features shape: {aligned_features.shape}\")\n    print(f\"Aligned targets shape: {aligned_targets.shape}\")\n    \n    # Check for NaN values\n    print(f\"NaN values in aligned features: {aligned_features.isna().sum().sum()}\")\n    print(f\"NaN values in aligned targets: {aligned_targets.isna().sum()}\")\n    \n    return aligned_features, aligned_targets\n\ndef train_wellbeing_models(X_train, y_train, X_val, y_val):\n    \"\"\"Train and evaluate multiple regression models for well-being scoring\"\"\"\n    \n    # First ensure data alignment\n    X_train, y_train = align_features_and_targets(X_train, y_train)\n    X_val, y_val = align_features_and_targets(X_val, y_val)\n    \n    # Handle any remaining NaN values in features\n    imputer = SimpleImputer(strategy='mean')\n    X_train_imputed = imputer.fit_transform(X_train)\n    X_val_imputed = imputer.transform(X_val)\n    \n    # Check for NaN values after imputation\n    print(f\"NaN values in training data after imputation: {np.isnan(X_train_imputed).sum()}\")\n    print(f\"NaN values in validation data after imputation: {np.isnan(X_val_imputed).sum()}\")\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train_imputed)\n    X_val_scaled = scaler.transform(X_val_imputed)\n    \n    # Model 1: Ridge Regression\n    print(\"Training Ridge Regression model...\")\n    ridge = Ridge(alpha=1.0)\n    ridge.fit(X_train_scaled, y_train)\n    ridge_preds = ridge.predict(X_val_scaled)\n    ridge_mse = mean_squared_error(y_val, ridge_preds)\n    \n    # Round predictions to nearest integer and clip to 1-10 range\n    ridge_preds_rounded = np.round(np.clip(ridge_preds, 1, 10)).astype(int)\n    ridge_mse_rounded = mean_squared_error(y_val, ridge_preds_rounded)\n    \n    print(f\"Ridge Regression MSE: {ridge_mse:.4f}, Rounded MSE: {ridge_mse_rounded:.4f}\")\n    \n    # Model 2: Random Forest\n    print(\"Training Random Forest model...\")\n    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n    rf.fit(X_train_imputed, y_train)\n    rf_preds = rf.predict(X_val_imputed)\n    rf_mse = mean_squared_error(y_val, rf_preds)\n    \n    # Round predictions to nearest integer and clip to 1-10 range\n    rf_preds_rounded = np.round(np.clip(rf_preds, 1, 10)).astype(int)\n    rf_mse_rounded = mean_squared_error(y_val, rf_preds_rounded)\n    \n    print(f\"Random Forest MSE: {rf_mse:.4f}, Rounded MSE: {rf_mse_rounded:.4f}\")\n    \n    # Model 3: Gradient Boosting\n    print(\"Training Gradient Boosting model...\")\n    gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n    gb.fit(X_train_imputed, y_train)\n    gb_preds = gb.predict(X_val_imputed)\n    gb_mse = mean_squared_error(y_val, gb_preds)\n    \n    # Round predictions to nearest integer and clip to 1-10 range\n    gb_preds_rounded = np.round(np.clip(gb_preds, 1, 10)).astype(int)\n    gb_mse_rounded = mean_squared_error(y_val, gb_preds_rounded)\n    \n    print(f\"Gradient Boosting MSE: {gb_mse:.4f}, Rounded MSE: {gb_mse_rounded:.4f}\")\n    \n    # Model 4: XGBoost\n    print(\"Training XGBoost model...\")\n    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n    xgb_model.fit(X_train_imputed, y_train)\n    xgb_preds = xgb_model.predict(X_val_imputed)\n    xgb_mse = mean_squared_error(y_val, xgb_preds)\n    \n    # Round predictions to nearest integer and clip to 1-10 range\n    xgb_preds_rounded = np.round(np.clip(xgb_preds, 1, 10)).astype(int)\n    xgb_mse_rounded = mean_squared_error(y_val, xgb_preds_rounded)\n    \n    print(f\"XGBoost MSE: {xgb_mse:.4f}, Rounded MSE: {xgb_mse_rounded:.4f}\")\n    \n    # Determine best model based on MSE\n    model_mse = {\n        'ridge': ridge_mse_rounded,\n        'rf': rf_mse_rounded,\n        'gb': gb_mse_rounded,\n        'xgb': xgb_mse_rounded\n    }\n    \n    best_model_name = min(model_mse, key=model_mse.get)\n    best_model_dict = {\n        'ridge': ridge,\n        'rf': rf,\n        'gb': gb,\n        'xgb': xgb_model\n    }\n    best_preds_dict = {\n        'ridge': ridge_preds_rounded,\n        'rf': rf_preds_rounded,\n        'gb': gb_preds_rounded,\n        'xgb': xgb_preds_rounded\n    }\n    \n    best_model = best_model_dict[best_model_name]\n    best_preds = best_preds_dict[best_model_name]\n    \n    print(f\"\\nBest model: {best_model_name.upper()} with MSE: {model_mse[best_model_name]:.4f}\")\n    \n    # Evaluate on score ranges\n    def eval_score_range(y_true, y_pred, range_min, range_max):\n        mask = (y_true >= range_min) & (y_true <= range_max)\n        if sum(mask) > 0:\n            return mean_squared_error(y_true[mask], y_pred[mask])\n        return 0\n    \n    low_range_mse = eval_score_range(y_val, best_preds, 1, 4)\n    mid_range_mse = eval_score_range(y_val, best_preds, 5, 6)\n    high_range_mse = eval_score_range(y_val, best_preds, 7, 10)\n    \n    print(f\"MSE for scores 1-4: {low_range_mse:.4f}\")\n    print(f\"MSE for scores 5-6: {mid_range_mse:.4f}\")\n    print(f\"MSE for scores 7-10: {high_range_mse:.4f}\")\n    \n    # Analyze feature importance\n    feature_importance = None\n    if hasattr(best_model, 'feature_importances_'):\n        feature_importance = {\n            column: float(importance) \n            for column, importance in zip(X_train.columns, best_model.feature_importances_)\n        }\n        # Print top 10 important features\n        sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n        print(\"\\nTop 10 important features:\")\n        for feature, importance in sorted_importance[:10]:\n            print(f\"{feature}: {importance:.4f}\")\n    \n    return {\n        'ridge': ridge,\n        'rf': rf,\n        'gb': gb,\n        'xgb': xgb_model,\n        'best_model': best_model,\n        'scaler': scaler,\n        'imputer': imputer,\n        'feature_importance': feature_importance,\n        'X_train_columns': X_train.columns.tolist()  # Store column names for prediction\n    }\n\n# Attempt to train the models with error handling\ntry:\n    print(\"=== Starting well-being model training ===\")\n    # Make sure train_target and val_target are series with indices\n    if not isinstance(train_target, pd.Series):\n        train_target = pd.Series(train_target, index=train_features_full.index)\n    if not isinstance(val_target, pd.Series):\n        val_target = pd.Series(val_target, index=val_features_full.index)\n    \n    # Train models using properly aligned data\n    models = train_wellbeing_models(\n        train_features_full, train_target,\n        val_features_full, val_target\n    )\n    print(\"Model training completed successfully!\")\nexcept Exception as e:\n    print(f\"Error during model training: {str(e)}\")\n    \n    # Create a more basic set of features if the full feature set fails\n    print(\"\\nTrying with a simpler feature set...\")\n    \n    # Extract basic features directly\n    def create_basic_features(texts, wellbeing_scores):\n        data = []\n        for text, score in zip(texts, wellbeing_scores):\n            # Basic text features\n            length = len(text)\n            word_count = len(text.split())\n            \n            # Simple sentiment features (without external libraries)\n            positive_words = ['good', 'great', 'happy', 'joy', 'excellent', 'love', 'positive', 'wonderful']\n            negative_words = ['bad', 'sad', 'angry', 'depressed', 'awful', 'hate', 'negative', 'terrible']\n            \n            pos_count = sum(1 for word in text.lower().split() if word in positive_words)\n            neg_count = sum(1 for word in text.lower().split() if word in negative_words)\n            \n            data.append({\n                'text_length': length,\n                'word_count': word_count,\n                'positive_word_count': pos_count,\n                'negative_word_count': neg_count,\n                'pos_neg_ratio': pos_count / (neg_count + 1),  # +1 to avoid division by zero\n                'wellbeing_score': score\n            })\n        \n        return pd.DataFrame(data)\n    \n    # Create simple features from text\n    train_texts = train_data['text'].tolist()\n    train_scores = train_data['wellbeing_score'].tolist()\n    val_texts = val_data['text'].tolist()\n    val_scores = val_data['wellbeing_score'].tolist()\n    \n    simple_train_df = create_basic_features(train_texts, train_scores)\n    simple_val_df = create_basic_features(val_texts, val_scores)\n    \n    # Split features and target\n    simple_train_features = simple_train_df.drop('wellbeing_score', axis=1)\n    simple_train_target = simple_train_df['wellbeing_score']\n    simple_val_features = simple_val_df.drop('wellbeing_score', axis=1)\n    simple_val_target = simple_val_df['wellbeing_score']\n    \n    # Try training with simple features\n    models = train_wellbeing_models(\n        simple_train_features, simple_train_target,\n        simple_val_features, simple_val_target\n    )\n    print(\"Model training completed with simplified feature set!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:05:29.510495Z","iopub.execute_input":"2025-03-08T22:05:29.510804Z","iopub.status.idle":"2025-03-08T22:05:30.817740Z","shell.execute_reply.started":"2025-03-08T22:05:29.510783Z","shell.execute_reply":"2025-03-08T22:05:30.816926Z"}},"outputs":[{"name":"stdout","text":"=== Starting well-being model training ===\nOriginal features shape: (189, 520)\nOriginal targets shape: (159,)\nNumber of common indices: 159\nAligned features shape: (159, 520)\nAligned targets shape: (159,)\nNaN values in aligned features: 15000\nNaN values in aligned targets: 0\nOriginal features shape: (75, 520)\nOriginal targets shape: (40,)\nNumber of common indices: 40\nAligned features shape: (40, 520)\nAligned targets shape: (40,)\nNaN values in aligned features: 17500\nNaN values in aligned targets: 0\nNaN values in training data after imputation: 0\nNaN values in validation data after imputation: 0\nTraining Ridge Regression model...\nRidge Regression MSE: 5.1417, Rounded MSE: 4.8250\nTraining Random Forest model...\nRandom Forest MSE: 2.3684, Rounded MSE: 2.5000\nTraining Gradient Boosting model...\nGradient Boosting MSE: 2.3795, Rounded MSE: 2.5000\nTraining XGBoost model...\nXGBoost MSE: 3.0928, Rounded MSE: 3.3750\n\nBest model: RF with MSE: 2.5000\nMSE for scores 1-4: 3.1667\nMSE for scores 5-6: 2.1875\nMSE for scores 7-10: 2.2500\n\nTop 10 important features:\nadaptive_ratio: 0.1764\nmentions_suicide: 0.0793\nmaladaptive_count: 0.0697\nsentiment_neg: 0.0608\nsentiment_compound: 0.0525\nsent_count: 0.0494\nsentiment_pos: 0.0339\nsentiment_neu: 0.0323\ntext_length: 0.0230\nword_count: 0.0179\nModel training completed successfully!\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nfrom sklearn.neural_network import MLPRegressor\n\ndef extract_bert_embeddings(texts, model_name=\"emilyalsentzer/Bio_ClinicalBERT\"):\n    \"\"\"\n    Extract BERT embeddings for texts\n    \n    Parameters:\n    texts (list): List of text strings\n    model_name (str): Pretrained model name\n    \n    Returns:\n    numpy.ndarray: BERT embeddings\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name)\n    \n    embeddings = []\n    batch_size = 8  # Process texts in batches\n    \n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting BERT embeddings\"):\n        batch_texts = texts[i:i+batch_size]\n        \n        # Tokenize and get attention masks\n        encoded = tokenizer(batch_texts, padding=True, truncation=True, \n                           return_tensors=\"pt\", max_length=512)\n        \n        # Extract embeddings\n        with torch.no_grad():\n            outputs = model(**encoded)\n            \n        # Use CLS token embedding as document representation\n        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n        embeddings.extend(batch_embeddings)\n    \n    return np.array(embeddings)\n\ndef train_neural_wellbeing_model(X_train, y_train, X_val, y_val):\n    \"\"\"Train neural network model for well-being prediction\"\"\"\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    \n    # Neural Network Regressor\n    nn_model = MLPRegressor(\n        hidden_layer_sizes=(100, 50),\n        activation='relu',\n        solver='adam',\n        alpha=0.001,\n        max_iter=500,\n        random_state=42\n    )\n    \n    # Train the model\n    nn_model.fit(X_train_scaled, y_train)\n    \n    # Predict and evaluate\n    nn_preds = nn_model.predict(X_val_scaled)\n    nn_preds_rounded = np.round(np.clip(nn_preds, 1, 10)).astype(int)\n    nn_mse = mean_squared_error(y_val, nn_preds_rounded)\n    \n    print(f\"Neural Network MSE: {nn_mse:.4f}\")\n    \n    return nn_model, scaler\n\n# Extract BERT embeddings for NLP-based well-being prediction\n# Note: This step is optional and can be resource-intensive\ntry:\n    print(\"Extracting BERT embeddings for training data...\")\n    train_bert_embeddings = extract_bert_embeddings(train_data['text'].tolist())\n    val_bert_embeddings = extract_bert_embeddings(val_data['text'].tolist())\n    \n    # Train a neural network using BERT embeddings\n    bert_nn_model, bert_scaler = train_neural_wellbeing_model(\n        train_bert_embeddings, train_target,\n        val_bert_embeddings, val_target\n    )\n    \n    # Add BERT model to the models dictionary\n    models['bert_nn'] = bert_nn_model\n    models['bert_scaler'] = bert_scaler\n    \nexcept Exception as e:\n    print(f\"Skipping BERT embeddings due to error: {str(e)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:05:47.054364Z","iopub.execute_input":"2025-03-08T22:05:47.054755Z","iopub.status.idle":"2025-03-08T22:07:52.094753Z","shell.execute_reply.started":"2025-03-08T22:05:47.054728Z","shell.execute_reply":"2025-03-08T22:07:52.093660Z"}},"outputs":[{"name":"stdout","text":"Extracting BERT embeddings for training data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dc0721b4ba245479027b80660fad970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59bebca3d64e4109b18e193db732e5f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5570fc20bc346fab31de334f9fe9c9e"}},"metadata":{}},{"name":"stderr","text":"Extracting BERT embeddings: 100%|██████████| 20/20 [01:20<00:00,  4.02s/it]\nExtracting BERT embeddings: 100%|██████████| 5/5 [00:22<00:00,  4.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Neural Network MSE: 4.0000\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\nimport pandas as pd\n\ndef create_ensemble_predictor(models, X_val, y_val):\n    \"\"\"\n    Create an ensemble predictor that combines multiple models with proper handling of NaN values\n    and feature name consistency\n    \n    Parameters:\n    models (dict): Dictionary of trained models\n    X_val (DataFrame): Validation features\n    y_val (Series): Validation targets\n    \n    Returns:\n    function: Ensemble prediction function\n    dict: Model weights\n    \"\"\"\n    print(f\"Creating ensemble predictor with {len(models)} models\")\n    print(f\"X_val shape: {X_val.shape}, NaN values: {X_val.isna().sum().sum()}\")\n    \n    # Ensure we have the imputer and scaler\n    imputer = models.get('imputer')\n    scaler = models.get('scaler')\n    \n    if imputer is None:\n        print(\"Warning: Imputer not found in models dictionary\")\n        # Create a simple imputer if none exists\n        from sklearn.impute import SimpleImputer\n        imputer = SimpleImputer(strategy='mean')\n        imputer.fit(X_val)\n        models['imputer'] = imputer\n    \n    # Get predictions from all available models\n    predictions = {}\n    \n    # Handle NaN values in validation data\n    X_val_imputed = pd.DataFrame(\n        imputer.transform(X_val), \n        columns=X_val.columns,\n        index=X_val.index\n    )\n    \n    print(f\"Imputed X_val shape: {X_val_imputed.shape}, NaN values: {X_val_imputed.isna().sum().sum()}\")\n    \n    # Make predictions with each model\n    if 'ridge' in models and models['ridge'] is not None:\n        try:\n            # Convert to numpy array to avoid feature name issues\n            X_scaled = scaler.transform(X_val_imputed.values)\n            ridge_preds = models['ridge'].predict(X_scaled)\n            predictions['ridge'] = np.round(np.clip(ridge_preds, 1, 10)).astype(int)\n            print(\"Successfully made Ridge predictions\")\n        except Exception as e:\n            print(f\"Error with Ridge model: {str(e)}\")\n    \n    if 'rf' in models and models['rf'] is not None:\n        try:\n            rf_preds = models['rf'].predict(X_val_imputed)\n            predictions['rf'] = np.round(np.clip(rf_preds, 1, 10)).astype(int)\n            print(\"Successfully made Random Forest predictions\")\n        except Exception as e:\n            print(f\"Error with Random Forest model: {str(e)}\")\n    \n    if 'gb' in models and models['gb'] is not None:\n        try:\n            gb_preds = models['gb'].predict(X_val_imputed)\n            predictions['gb'] = np.round(np.clip(gb_preds, 1, 10)).astype(int)\n            print(\"Successfully made Gradient Boosting predictions\")\n        except Exception as e:\n            print(f\"Error with Gradient Boosting model: {str(e)}\")\n    \n    if 'xgb' in models and models['xgb'] is not None:\n        try:\n            xgb_preds = models['xgb'].predict(X_val_imputed)\n            predictions['xgb'] = np.round(np.clip(xgb_preds, 1, 10)).astype(int)\n            print(\"Successfully made XGBoost predictions\")\n        except Exception as e:\n            print(f\"Error with XGBoost model: {str(e)}\")\n    \n    # If no models could make predictions, use a fallback\n    if not predictions:\n        print(\"No models could make predictions. Using default predictor.\")\n        # Return a function that always predicts middle score (5)\n        return (lambda x, **kwargs: 5), {'default': 1.0}\n    \n    # Optimize model weights based on MSE\n    weights = {}\n    for model_name, preds in predictions.items():\n        mse = mean_squared_error(y_val, preds)\n        print(f\"{model_name.upper()} MSE: {mse:.4f}\")\n        # Use inverse MSE as weight (better models get higher weights)\n        weights[model_name] = 1 / mse if mse > 0 else 1\n    \n    # Normalize weights\n    total_weight = sum(weights.values())\n    for model_name in weights:\n        weights[model_name] /= total_weight\n    \n    print(\"Ensemble model weights:\")\n    for model_name, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n        print(f\"{model_name}: {weight:.4f}\")\n    \n    # Create ensemble prediction function\n    def predict_ensemble(features, **kwargs):\n        \"\"\"\n        Make well-being score predictions using ensemble\n        \n        Parameters:\n        features (DataFrame): Features for traditional models\n        **kwargs: Additional arguments (ignored)\n        \n        Returns:\n        int: Predicted well-being score (1-10)\n        \"\"\"\n        # Ensure we're predicting for a single sample\n        if len(features.shape) > 1 and features.shape[0] > 1:\n            print(f\"Warning: Predicting for first sample only. Received {features.shape[0]} samples.\")\n            if isinstance(features, pd.DataFrame):\n                features = features.iloc[[0]]\n            else:\n                features = features[[0], :]\n        \n        # Preprocess: handle NaN values\n        try:\n            if isinstance(features, pd.DataFrame):\n                features_imputed = pd.DataFrame(\n                    imputer.transform(features),\n                    columns=features.columns,\n                    index=features.index\n                )\n            else:\n                features_imputed = imputer.transform(features)\n        except Exception as e:\n            print(f\"Error in imputation: {str(e)}\")\n            return 5  # Default middle score if preprocessing fails\n        \n        # Collect predictions from each model\n        model_predictions = []\n        model_weights = []\n        \n        # Ridge model (needs scaling)\n        if 'ridge' in weights:\n            try:\n                X_scaled = scaler.transform(features_imputed.values if isinstance(features_imputed, pd.DataFrame) \n                                          else features_imputed)\n                ridge_pred = models['ridge'].predict(X_scaled)[0]\n                model_predictions.append(int(np.round(np.clip(ridge_pred, 1, 10))))\n                model_weights.append(weights['ridge'])\n            except Exception as e:\n                print(f\"Ridge prediction error: {str(e)}\")\n        \n        # Random Forest model\n        if 'rf' in weights:\n            try:\n                rf_pred = models['rf'].predict(features_imputed)[0]\n                model_predictions.append(int(np.round(np.clip(rf_pred, 1, 10))))\n                model_weights.append(weights['rf'])\n            except Exception as e:\n                print(f\"Random Forest prediction error: {str(e)}\")\n        \n        # Gradient Boosting model\n        if 'gb' in weights:\n            try:\n                gb_pred = models['gb'].predict(features_imputed)[0]\n                model_predictions.append(int(np.round(np.clip(gb_pred, 1, 10))))\n                model_weights.append(weights['gb'])\n            except Exception as e:\n                print(f\"Gradient Boosting prediction error: {str(e)}\")\n        \n        # XGBoost model\n        if 'xgb' in weights:\n            try:\n                xgb_pred = models['xgb'].predict(features_imputed)[0]\n                model_predictions.append(int(np.round(np.clip(xgb_pred, 1, 10))))\n                model_weights.append(weights['xgb'])\n            except Exception as e:\n                print(f\"XGBoost prediction error: {str(e)}\")\n        \n        # If we have predictions, compute weighted average\n        if model_predictions:\n            # Weighted average\n            weighted_pred = sum(p * w for p, w in zip(model_predictions, model_weights)) / sum(model_weights)\n            final_pred = int(np.round(np.clip(weighted_pred, 1, 10)))\n            return final_pred\n        else:\n            # If all models failed, return middle score\n            print(\"All models failed to predict, returning default score\")\n            return 5\n    \n    return predict_ensemble, weights\n\n# Create ensemble predictor with error handling\ntry:\n    print(\"\\n=== Creating ensemble predictor ===\")\n    # First ensure that validation data is aligned with targets\n    if isinstance(val_target, pd.Series):\n        X_val_aligned = val_features_full.loc[val_target.index]\n    else:\n        X_val_aligned = val_features_full\n        \n    # Now create the ensemble predictor\n    ensemble_predictor, model_weights = create_ensemble_predictor(\n        models, X_val_aligned, val_target\n    )\n    print(\"Successfully created ensemble predictor\")\nexcept Exception as e:\n    print(f\"Failed to create ensemble predictor: {str(e)}\")\n    # Fallback to best model\n    if 'best_model' in models and models['best_model'] is not None:\n        print(\"Using best model as fallback\")\n        best_model = models['best_model']\n        imputer = models.get('imputer')\n        scaler = models.get('scaler')\n        \n        def simple_predictor(features, **kwargs):\n            try:\n                # Basic preprocessing\n                if imputer is not None:\n                    features_imputed = imputer.transform(features)\n                else:\n                    features_imputed = features\n                \n                # Check if best model is Ridge (needs scaling)\n                if hasattr(best_model, 'intercept_') and scaler is not None:\n                    features_scaled = scaler.transform(features_imputed)\n                    pred = best_model.predict(features_scaled)[0]\n                else:\n                    pred = best_model.predict(features_imputed)[0]\n                \n                return int(np.round(np.clip(pred, 1, 10)))\n            except Exception as e:\n                print(f\"Error in simple predictor: {str(e)}\")\n                return 5  # Default middle score\n        \n        ensemble_predictor = simple_predictor\n        model_weights = {'best_model': 1.0}\n    else:\n        print(\"No best model available, using default predictor\")\n        # Just return middle score\n        ensemble_predictor = lambda x, **kwargs: 5\n        model_weights = {'default': 1.0}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:15:38.545472Z","iopub.execute_input":"2025-03-08T22:15:38.545795Z","iopub.status.idle":"2025-03-08T22:15:38.658151Z","shell.execute_reply.started":"2025-03-08T22:15:38.545773Z","shell.execute_reply":"2025-03-08T22:15:38.657182Z"}},"outputs":[{"name":"stdout","text":"\n=== Creating ensemble predictor ===\nCreating ensemble predictor with 11 models\nX_val shape: (40, 520), NaN values: 17500\nImputed X_val shape: (40, 520), NaN values: 0\nSuccessfully made Ridge predictions\nSuccessfully made Random Forest predictions\nSuccessfully made Gradient Boosting predictions\nSuccessfully made XGBoost predictions\nRIDGE MSE: 4.8250\nRF MSE: 2.5000\nGB MSE: 2.5000\nXGB MSE: 3.3750\nEnsemble model weights:\nrf: 0.3069\ngb: 0.3069\nxgb: 0.2273\nridge: 0.1590\nSuccessfully created ensemble predictor\n","output_type":"stream"},{"name":"stderr","text":"X has feature names, but RandomForestRegressor was fitted without feature names\nX has feature names, but GradientBoostingRegressor was fitted without feature names\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"def predict_wellbeing_for_post(post_text, previous_posts, adaptive_evidence, maladaptive_evidence, \n                              models, vectorizer, ensemble_predictor=None):\n    \"\"\"\n    Predict well-being score for a new post\n    \n    Parameters:\n    post_text (str): Text content of the post\n    previous_posts (list): List of previous post texts\n    adaptive_evidence (list): Extracted adaptive evidence spans\n    maladaptive_evidence (list): Extracted maladaptive evidence spans\n    models (dict): Trained models\n    vectorizer (TfidfVectorizer): Fitted vectorizer\n    ensemble_predictor (function, optional): Ensemble prediction function\n    \n    Returns:\n    int: Predicted well-being score (1-10)\n    \"\"\"\n    # Create a DataFrame with the post\n    post_df = pd.DataFrame([{\n        'text': post_text,\n        'adaptive_evidence': adaptive_evidence,\n        'maladaptive_evidence': maladaptive_evidence,\n        'previous_posts': previous_posts\n    }])\n    \n    # Extract features\n    features = extract_wellbeing_features(post_df)\n    \n    # Add text vectorization features\n    tfidf = vectorizer.transform([post_text])\n    tfidf_df = pd.DataFrame(\n        tfidf.toarray(), \n        columns=[f'tfidf_{i}' for i in range(tfidf.shape[1])]\n    )\n    \n    # Combine all features\n    features_full = pd.concat([features, tfidf_df], axis=1)\n    \n    # If ensemble predictor is available, use it\n    if ensemble_predictor is not None:\n        return ensemble_predictor(features_full)\n    \n    # Otherwise, use the best model\n    best_model = models['best_model']\n    prediction = best_model.predict(features_full)[0]\n    \n    # Round to nearest integer and clip to 1-10 range\n    final_prediction = int(np.round(np.clip(prediction, 1, 10)))\n    \n    return final_prediction\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:16:15.743301Z","iopub.execute_input":"2025-03-08T22:16:15.743711Z","iopub.status.idle":"2025-03-08T22:16:15.750188Z","shell.execute_reply.started":"2025-03-08T22:16:15.743682Z","shell.execute_reply":"2025-03-08T22:16:15.749382Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def process_timeline_for_taskA(timeline, adaptive_clf, maladaptive_clf, vectorizer, feature_names,\n                              wellbeing_models, adaptive_importance=None, maladaptive_importance=None,\n                              ensemble_predictor=None):\n    \"\"\"\n    Process a test timeline for Task A (both A1 and A2)\n    \n    Parameters:\n    timeline (dict): Timeline data\n    adaptive_clf, maladaptive_clf: Classifiers from Task A1\n    vectorizer: TF-IDF vectorizer\n    feature_names: Feature names for the vectorizer\n    wellbeing_models (dict): Trained well-being prediction models\n    adaptive_importance, maladaptive_importance: Feature importance dictionaries\n    ensemble_predictor: Ensemble prediction function\n    \n    Returns:\n    tuple: (timeline_id, result dictionary)\n    \"\"\"\n    timeline_id = timeline[\"timeline_id\"]\n    result = {\n        \"timeline_level\": {\"summary\": \"\"},  # Will be filled by Task C\n        \"post_level\": {}\n    }\n    \n    # Keep track of previous posts for context\n    previous_posts = []\n    \n    for post in timeline[\"posts\"]:\n        post_id = post[\"post_id\"]\n        post_text = post[\"post\"] if \"post\" in post else \"\"\n        \n        if not post_text:\n            # Handle empty posts\n            result[\"post_level\"][post_id] = {\n                \"adaptive_evidence\": [],\n                \"maladaptive_evidence\": [],\n                \"summary\": \"\",\n                \"wellbeing_score\": None\n            }\n            continue\n        \n        # Task A.1: Extract adaptive and maladaptive evidence\n        adaptive_spans = extract_evidence_spans(\n            post_text, adaptive_clf, vectorizer, feature_names,\n            feature_importance=adaptive_importance\n        )\n        adaptive_spans = consolidate_spans(adaptive_spans, post_text)\n        \n        maladaptive_spans = extract_evidence_spans(\n            post_text, maladaptive_clf, vectorizer, feature_names,\n            feature_importance=maladaptive_importance\n        )\n        maladaptive_spans = consolidate_spans(maladaptive_spans, post_text)\n        \n        # Task A.2: Predict well-being score\n        wellbeing_score = predict_wellbeing_for_post(\n            post_text, previous_posts, adaptive_spans, maladaptive_spans,\n            wellbeing_models, vectorizer, ensemble_predictor\n        )\n        \n        # Add to results\n        result[\"post_level\"][post_id] = {\n            \"adaptive_evidence\": adaptive_spans,\n            \"maladaptive_evidence\": maladaptive_spans,\n            \"summary\": \"\",  # Will be filled by Task B\n            \"wellbeing_score\": wellbeing_score\n        }\n        \n        # Update previous posts for context\n        previous_posts.append(post_text)\n        if len(previous_posts) > 5:  # Keep only last 5 posts for context\n            previous_posts = previous_posts[-5:]\n    \n    return timeline_id, result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:16:20.693504Z","iopub.execute_input":"2025-03-08T22:16:20.693811Z","iopub.status.idle":"2025-03-08T22:16:20.701454Z","shell.execute_reply.started":"2025-03-08T22:16:20.693790Z","shell.execute_reply":"2025-03-08T22:16:20.700377Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\ndef run_full_taskA_pipeline(train_dir, test_dir, output_path, team_name=\"MyTeam\"):\n    \"\"\"Run the complete Task A pipeline (A1 and A2) from training to submission generation\"\"\"\n    print(\"Loading training data...\")\n    train_timelines = load_all_timelines(train_dir)\n    \n    # Task A.1 data preparation\n    train_df_a1 = create_training_dataset(train_timelines)\n    train_df_a1 = analyze_dataset(train_df_a1)\n    \n    # Task A.2 data preparation\n    wellbeing_df = extract_wellbeing_data(train_timelines)\n    \n    print(\"Splitting data...\")\n    # Split data for both tasks\n    train_data_a1, val_data_a1 = train_test_split(train_df_a1, test_size=0.2, random_state=42)\n    train_data_a2, val_data_a2 = train_test_split(wellbeing_df, test_size=0.2, random_state=42)\n    \n    print(\"Training Task A.1 classifiers...\")\n    # Task A.1: Feature engineering and model training\n    X_train_a1, vectorizer, feature_names = engineer_features(train_data_a1)\n    X_val_a1 = vectorizer.transform(val_data_a1['text'])\n    \n    adaptive_clf, maladaptive_clf = train_binary_classifiers(\n        X_train_a1, train_data_a1['has_adaptive'], train_data_a1['has_maladaptive'],\n        X_val_a1, val_data_a1['has_adaptive'], val_data_a1['has_maladaptive']\n    )\n    \n    # Calculate feature importance for Task A.1\n    adaptive_importance = calculate_feature_importance_simple(adaptive_clf, feature_names)\n    maladaptive_importance = calculate_feature_importance_simple(maladaptive_clf, feature_names)\n    \n    print(\"Training Task A.2 models...\")\n    # Task A.2: Feature engineering and model training\n    train_features_a2 = extract_wellbeing_features(train_data_a2)\n    val_features_a2 = extract_wellbeing_features(val_data_a2)\n    \n    # Add text vectorization features\n    train_tfidf_a2 = vectorizer.transform(train_data_a2['text'])\n    val_tfidf_a2 = vectorizer.transform(val_data_a2['text'])\n    \n    # Ensure indices are preserved during DataFrame creation\n    train_tfidf_df_a2 = pd.DataFrame(\n        train_tfidf_a2.toarray(), \n        columns=[f'tfidf_{i}' for i in range(train_tfidf_a2.shape[1])],\n        index=train_data_a2.index  # Preserve index alignment\n    )\n    val_tfidf_df_a2 = pd.DataFrame(\n        val_tfidf_a2.toarray(), \n        columns=[f'tfidf_{i}' for i in range(val_tfidf_a2.shape[1])],\n        index=val_data_a2.index  # Preserve index alignment\n    )\n    \n    # Ensure train_features_a2 and val_features_a2 have proper indices\n    train_features_a2.index = train_data_a2.index\n    val_features_a2.index = val_data_a2.index\n    \n    # Concatenate features with preserved indices\n    train_features_full_a2 = pd.concat([train_features_a2, train_tfidf_df_a2], axis=1)\n    val_features_full_a2 = pd.concat([val_features_a2, val_tfidf_df_a2], axis=1)\n    \n    # Ensure targets are Series with preserved indices\n    train_target_a2 = pd.Series(train_data_a2['wellbeing_score'].values, index=train_data_a2.index)\n    val_target_a2 = pd.Series(val_data_a2['wellbeing_score'].values, index=val_data_a2.index)\n    \n    # Train well-being models with properly aligned data\n    wellbeing_models = train_wellbeing_models(\n        train_features_full_a2, train_target_a2,\n        val_features_full_a2, val_target_a2\n    )\n    \n    print(\"Creating ensemble predictor...\")\n    # Create ensemble predictor using aligned data\n    ensemble_predictor, model_weights = create_aligned_ensemble_predictor(\n        wellbeing_models, val_features_full_a2, val_target_a2\n    )\n    \n    print(\"Processing test data...\")\n    test_timelines = load_all_timelines(test_dir)\n    \n    submission = {}\n    for timeline in tqdm(test_timelines, desc=\"Processing test timelines\"):\n        timeline_id, result = process_timeline_for_taskA(\n            timeline, adaptive_clf, maladaptive_clf, vectorizer, feature_names,\n            wellbeing_models, adaptive_importance, maladaptive_importance,\n            ensemble_predictor\n        )\n        submission[timeline_id] = result\n    \n    print(\"Saving submission...\")\n    os.makedirs(output_path, exist_ok=True)\n    output_file = os.path.join(output_path, f\"{team_name}_TaskA.json\")\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(submission, f, ensure_ascii=False, indent=2)\n    \n    print(f\"Task A processing complete! Submission saved to {output_file}\")\n    return submission\n\ndef create_aligned_ensemble_predictor(models, X_val, y_val):\n    \"\"\"\n    Create an ensemble predictor that combines multiple models with proper data alignment\n    \n    Parameters:\n    models (dict): Dictionary of trained models\n    X_val (DataFrame): Validation features\n    y_val (Series): Validation targets\n    \n    Returns:\n    function: Ensemble prediction function\n    dict: Model weights\n    \"\"\"\n    print(f\"Creating ensemble predictor with {len(models)} models\")\n    \n    # Ensure X_val and y_val are properly aligned by index\n    common_indices = X_val.index.intersection(y_val.index)\n    print(f\"Original X_val shape: {X_val.shape}, y_val shape: {len(y_val)}\")\n    print(f\"Common indices: {len(common_indices)}\")\n    \n    # Filter both dataframes to only include common indices\n    X_val_aligned = X_val.loc[common_indices]\n    y_val_aligned = y_val.loc[common_indices]\n    \n    print(f\"Aligned X_val shape: {X_val_aligned.shape}, y_val shape: {len(y_val_aligned)}\")\n    \n    # Ensure we have the imputer and scaler\n    imputer = models.get('imputer')\n    scaler = models.get('scaler')\n    \n    if imputer is None:\n        print(\"Warning: Imputer not found in models dictionary\")\n        from sklearn.impute import SimpleImputer\n        imputer = SimpleImputer(strategy='mean')\n        imputer.fit(X_val_aligned)\n        models['imputer'] = imputer\n    \n    # Handle NaN values in validation data\n    X_val_imputed = pd.DataFrame(\n        imputer.transform(X_val_aligned), \n        columns=X_val_aligned.columns,\n        index=X_val_aligned.index\n    )\n    \n    print(f\"Imputed X_val shape: {X_val_imputed.shape}, NaN values: {X_val_imputed.isna().sum().sum()}\")\n    \n    # Get predictions from all available models\n    predictions = {}\n    \n    # Make predictions with each model\n    if 'ridge' in models and models['ridge'] is not None:\n        try:\n            # Convert to numpy array to avoid feature name issues\n            X_scaled = scaler.transform(X_val_imputed.values)\n            ridge_preds = models['ridge'].predict(X_scaled)\n            predictions['ridge'] = np.round(np.clip(ridge_preds, 1, 10)).astype(int)\n            print(\"Successfully made Ridge predictions\")\n        except Exception as e:\n            print(f\"Error with Ridge model: {str(e)}\")\n    \n    if 'rf' in models and models['rf'] is not None:\n        try:\n            # Convert to numpy array to avoid feature name issues\n            rf_preds = models['rf'].predict(X_val_imputed.values)\n            predictions['rf'] = np.round(np.clip(rf_preds, 1, 10)).astype(int)\n            print(\"Successfully made Random Forest predictions\")\n        except Exception as e:\n            print(f\"Error with Random Forest model: {str(e)}\")\n    \n    if 'gb' in models and models['gb'] is not None:\n        try:\n            # Convert to numpy array to avoid feature name issues\n            gb_preds = models['gb'].predict(X_val_imputed.values)\n            predictions['gb'] = np.round(np.clip(gb_preds, 1, 10)).astype(int)\n            print(\"Successfully made Gradient Boosting predictions\")\n        except Exception as e:\n            print(f\"Error with Gradient Boosting model: {str(e)}\")\n    \n    if 'xgb' in models and models['xgb'] is not None:\n        try:\n            # Convert to numpy array to avoid feature name issues\n            xgb_preds = models['xgb'].predict(X_val_imputed.values)\n            predictions['xgb'] = np.round(np.clip(xgb_preds, 1, 10)).astype(int)\n            print(\"Successfully made XGBoost predictions\")\n        except Exception as e:\n            print(f\"Error with XGBoost model: {str(e)}\")\n    \n    # If no models could make predictions, use a fallback\n    if not predictions:\n        print(\"No models could make predictions. Using default predictor.\")\n        return (lambda x, **kwargs: 5), {'default': 1.0}\n    \n    # Optimize model weights based on MSE\n    weights = {}\n    for model_name, preds in predictions.items():\n        # Now y_val_aligned and preds should have the same length\n        mse = mean_squared_error(y_val_aligned, preds)\n        print(f\"{model_name.upper()} MSE: {mse:.4f}\")\n        # Use inverse MSE as weight (better models get higher weights)\n        weights[model_name] = 1 / mse if mse > 0 else 1\n    \n    # Normalize weights\n    total_weight = sum(weights.values())\n    for model_name in weights:\n        weights[model_name] /= total_weight\n    \n    print(\"Ensemble model weights:\")\n    for model_name, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n        print(f\"{model_name}: {weight:.4f}\")\n    \n    # Create ensemble prediction function\n    def predict_ensemble(features, **kwargs):\n        \"\"\"\n        Make well-being score predictions using ensemble\n        \n        Parameters:\n        features (DataFrame): Features for traditional models\n        **kwargs: Additional arguments (ignored)\n        \n        Returns:\n        int: Predicted well-being score (1-10)\n        \"\"\"\n        # Ensure we're predicting for a single sample\n        if len(features.shape) > 1 and features.shape[0] > 1:\n            print(f\"Warning: Predicting for first sample only. Received {features.shape[0]} samples.\")\n            if isinstance(features, pd.DataFrame):\n                features = features.iloc[[0]]\n            else:\n                features = features[[0], :]\n        \n        # Preprocess: handle NaN values\n        try:\n            if isinstance(features, pd.DataFrame):\n                features_imputed = pd.DataFrame(\n                    imputer.transform(features),\n                    columns=features.columns,\n                    index=features.index\n                )\n            else:\n                features_imputed = imputer.transform(features)\n        except Exception as e:\n            print(f\"Error in imputation: {str(e)}\")\n            return 5  # Default middle score if preprocessing fails\n        \n        # Collect predictions from each model\n        model_predictions = []\n        model_weights = []\n        \n        # Ridge model (needs scaling)\n        if 'ridge' in weights:\n            try:\n                # Convert to numpy array to avoid feature name issues\n                X_scaled = scaler.transform(features_imputed.values if isinstance(features_imputed, pd.DataFrame) \n                                          else features_imputed)\n                ridge_pred = models['ridge'].predict(X_scaled)[0]\n                model_predictions.append(int(np.round(np.clip(ridge_pred, 1, 10))))\n                model_weights.append(weights['ridge'])\n            except Exception as e:\n                print(f\"Ridge prediction error: {str(e)}\")\n        \n        # Random Forest model\n        if 'rf' in weights:\n            try:\n                # Convert to numpy array to avoid feature name issues\n                rf_pred = models['rf'].predict(\n                    features_imputed.values if isinstance(features_imputed, pd.DataFrame) \n                    else features_imputed\n                )[0]\n                model_predictions.append(int(np.round(np.clip(rf_pred, 1, 10))))\n                model_weights.append(weights['rf'])\n            except Exception as e:\n                print(f\"Random Forest prediction error: {str(e)}\")\n        \n        # Gradient Boosting model\n        if 'gb' in weights:\n            try:\n                # Convert to numpy array to avoid feature name issues\n                gb_pred = models['gb'].predict(\n                    features_imputed.values if isinstance(features_imputed, pd.DataFrame) \n                    else features_imputed\n                )[0]\n                model_predictions.append(int(np.round(np.clip(gb_pred, 1, 10))))\n                model_weights.append(weights['gb'])\n            except Exception as e:\n                print(f\"Gradient Boosting prediction error: {str(e)}\")\n        \n        # XGBoost model\n        if 'xgb' in weights:\n            try:\n                # Convert to numpy array to avoid feature name issues\n                xgb_pred = models['xgb'].predict(\n                    features_imputed.values if isinstance(features_imputed, pd.DataFrame) \n                    else features_imputed\n                )[0]\n                model_predictions.append(int(np.round(np.clip(xgb_pred, 1, 10))))\n                model_weights.append(weights['xgb'])\n            except Exception as e:\n                print(f\"XGBoost prediction error: {str(e)}\")\n        \n        # If we have predictions, compute weighted average\n        if model_predictions:\n            # Weighted average\n            weighted_pred = sum(p * w for p, w in zip(model_predictions, model_weights)) / sum(model_weights)\n            final_pred = int(np.round(np.clip(weighted_pred, 1, 10)))\n            return final_pred\n        else:\n            # If all models failed, return middle score\n            print(\"All models failed to predict, returning default score\")\n            return 5\n    \n    return predict_ensemble, weights\n\n# Main execution\nif __name__ == \"__main__\":\n    # Configuration\n    TRAIN_DIR = \"/kaggle/input/train-dataset-1\"\n    TEST_DIR = \"/kaggle/input/test-dataset-1\"\n    OUTPUT_DIR = \"/kaggle/working/\"\n    TEAM_NAME = \"CIOL\"\n    \n    # Run the pipeline\n    submission = run_full_taskA_pipeline(TRAIN_DIR, TEST_DIR, OUTPUT_DIR, TEAM_NAME)\n    \n    print(\"Task A completed successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:23:02.250054Z","iopub.execute_input":"2025-03-08T22:23:02.250385Z","iopub.status.idle":"2025-03-08T22:23:20.698600Z","shell.execute_reply.started":"2025-03-08T22:23:02.250360Z","shell.execute_reply":"2025-03-08T22:23:20.697524Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nTotal posts: 343\nPosts with adaptive evidence: 169\nPosts with maladaptive evidence: 179\nSplitting data...\nTraining Task A.1 classifiers...\nAdaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.79      0.81      0.80        37\n           1       0.77      0.75      0.76        32\n\n    accuracy                           0.78        69\n   macro avg       0.78      0.78      0.78        69\nweighted avg       0.78      0.78      0.78        69\n\nMaladaptive Classifier Performance:\n              precision    recall  f1-score   support\n\n           0       0.94      0.83      0.88        41\n           1       0.79      0.93      0.85        28\n\n    accuracy                           0.87        69\n   macro avg       0.87      0.88      0.87        69\nweighted avg       0.88      0.87      0.87        69\n\nTraining Task A.2 models...\nOriginal features shape: (159, 5020)\nOriginal targets shape: (159,)\nNumber of common indices: 159\nAligned features shape: (159, 5020)\nAligned targets shape: (159,)\nNaN values in aligned features: 0\nNaN values in aligned targets: 0\nOriginal features shape: (40, 5020)\nOriginal targets shape: (40,)\nNumber of common indices: 40\nAligned features shape: (40, 5020)\nAligned targets shape: (40,)\nNaN values in aligned features: 0\nNaN values in aligned targets: 0\nNaN values in training data after imputation: 0\nNaN values in validation data after imputation: 0\nTraining Ridge Regression model...\nRidge Regression MSE: 2.2317, Rounded MSE: 2.3250\nTraining Random Forest model...\nRandom Forest MSE: 2.2301, Rounded MSE: 2.3500\nTraining Gradient Boosting model...\nGradient Boosting MSE: 2.3634, Rounded MSE: 2.3000\nTraining XGBoost model...\nXGBoost MSE: 2.2215, Rounded MSE: 2.2750\n\nBest model: XGB with MSE: 2.2750\nMSE for scores 1-4: 3.0000\nMSE for scores 5-6: 1.5625\nMSE for scores 7-10: 2.5000\n\nTop 10 important features:\ntfidf_2356: 0.0834\ntfidf_1308: 0.0584\nadaptive_ratio: 0.0536\ntfidf_2254: 0.0503\nmentions_suicide: 0.0459\ntfidf_4331: 0.0452\ntfidf_1229: 0.0414\ntfidf_3908: 0.0395\ntfidf_2513: 0.0358\ntfidf_2482: 0.0297\nCreating ensemble predictor...\nCreating ensemble predictor with 9 models\nOriginal X_val shape: (40, 5020), y_val shape: 40\nCommon indices: 40\nAligned X_val shape: (40, 5020), y_val shape: 40\nImputed X_val shape: (40, 5020), NaN values: 0\nSuccessfully made Ridge predictions\nSuccessfully made Random Forest predictions\nSuccessfully made Gradient Boosting predictions\nSuccessfully made XGBoost predictions\nRIDGE MSE: 2.3250\nRF MSE: 2.3500\nGB MSE: 2.3000\nXGB MSE: 2.2750\nEnsemble model weights:\nxgb: 0.2541\ngb: 0.2513\nridge: 0.2486\nrf: 0.2460\nProcessing test data...\n","output_type":"stream"},{"name":"stderr","text":"Processing test timelines: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Saving submission...\nTask A processing complete! Submission saved to /kaggle/working/CIOL_TaskA.json\nTask A completed successfully!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":42}]}